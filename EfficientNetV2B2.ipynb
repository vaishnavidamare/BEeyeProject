{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0551d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "\n",
    "input_folder = r\"C:\\Users\\admin\\OneDrive\\BE project\\BEeyeProject\\dataset\"\n",
    "output_folder = r\"C:\\Users\\admin\\OneDrive\\BE project\\BEeyeProject\\dataset-split\"\n",
    "\n",
    "splitfolders.ratio(input_folder, output_folder, seed=42, ratio=(0.7, 0.2, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5fe6127-ef3b-496d-af72-7d16b609a57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4314 images belonging to 5 classes.\n",
      "Found 536 images belonging to 5 classes.\n",
      "4314\n",
      "536\n",
      "{'diabetic_retinopathy', 'cataract', 'AMD', 'glaucoma', 'normal'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_data_dir=r\"dataset-split/train\"\n",
    "val_data_dir=r\"dataset-split/val\"\n",
    "\n",
    "# from keras.layers.preprocessing.image_preprocessing import HORIZONTAL\n",
    "\n",
    "train_datagen=ImageDataGenerator(horizontal_flip= True)\n",
    "\n",
    "val_datagen=ImageDataGenerator()\n",
    "\n",
    "img_width,img_height=224,224\n",
    "batch_size=32\n",
    "train_generator=train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                  target_size=(img_height,img_width),\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  \n",
    "                                                  shuffle= True,\n",
    "                                                  class_mode='categorical')\n",
    "\n",
    "val_generator=val_datagen.flow_from_directory(val_data_dir,\n",
    "                                              target_size=(img_height,img_width),\n",
    "                                              batch_size=batch_size,\n",
    "                                         \n",
    "                                              shuffle= False,\n",
    "                                              class_mode='categorical')\n",
    "\n",
    "train_class_names = set()\n",
    "num_train_samples=0\n",
    "for i in train_generator.filenames:\n",
    "    train_class_names.add(i.split('\\\\')[0])\n",
    "    num_train_samples+=1\n",
    "print(num_train_samples)\n",
    "train_class_names\n",
    "\n",
    "val_class_names = set()\n",
    "num_val_samples=0\n",
    "for i in val_generator.filenames:\n",
    "    val_class_names.add(i.split('/')[0])\n",
    "    num_val_samples+=1\n",
    "print(num_val_samples)\n",
    "print(val_class_names)\n",
    "\n",
    "num_classes = len(val_class_names)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e815a586-8b80-4b66-ba17-09649a456f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-13 13:42:28.302560: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-13 13:42:28.437848: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-13 13:42:28.443523: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-13 13:42:28.448623: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-13 13:42:28.452629: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-13 13:42:28.456115: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-13 13:42:28.597698: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-13 13:42:28.599332: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-13 13:42:28.600752: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-13 13:42:28.602188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13981 MB memory:  -> device: 0, name: NVIDIA RTX A4000, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"efficientnetv2-b2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " rescaling (Rescaling)       (None, 224, 224, 3)          0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " normalization (Normalizati  (None, 224, 224, 3)          0         ['rescaling[0][0]']           \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " stem_conv (Conv2D)          (None, 112, 112, 32)         864       ['normalization[0][0]']       \n",
      "                                                                                                  \n",
      " stem_bn (BatchNormalizatio  (None, 112, 112, 32)         128       ['stem_conv[0][0]']           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stem_activation (Activatio  (None, 112, 112, 32)         0         ['stem_bn[0][0]']             \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block1a_project_conv (Conv  (None, 112, 112, 16)         4608      ['stem_activation[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block1a_project_bn (BatchN  (None, 112, 112, 16)         64        ['block1a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block1a_project_activation  (None, 112, 112, 16)         0         ['block1a_project_bn[0][0]']  \n",
      "  (Activation)                                                                                    \n",
      "                                                                                                  \n",
      " block1b_project_conv (Conv  (None, 112, 112, 16)         2304      ['block1a_project_activation[0\n",
      " 2D)                                                                ][0]']                        \n",
      "                                                                                                  \n",
      " block1b_project_bn (BatchN  (None, 112, 112, 16)         64        ['block1b_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block1b_project_activation  (None, 112, 112, 16)         0         ['block1b_project_bn[0][0]']  \n",
      "  (Activation)                                                                                    \n",
      "                                                                                                  \n",
      " block1b_drop (Dropout)      (None, 112, 112, 16)         0         ['block1b_project_activation[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " block1b_add (Add)           (None, 112, 112, 16)         0         ['block1b_drop[0][0]',        \n",
      "                                                                     'block1a_project_activation[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " block2a_expand_conv (Conv2  (None, 56, 56, 64)           9216      ['block1b_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block2a_expand_bn (BatchNo  (None, 56, 56, 64)           256       ['block2a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block2a_expand_activation   (None, 56, 56, 64)           0         ['block2a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block2a_project_conv (Conv  (None, 56, 56, 32)           2048      ['block2a_expand_activation[0]\n",
      " 2D)                                                                [0]']                         \n",
      "                                                                                                  \n",
      " block2a_project_bn (BatchN  (None, 56, 56, 32)           128       ['block2a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block2b_expand_conv (Conv2  (None, 56, 56, 128)          36864     ['block2a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block2b_expand_bn (BatchNo  (None, 56, 56, 128)          512       ['block2b_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block2b_expand_activation   (None, 56, 56, 128)          0         ['block2b_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block2b_project_conv (Conv  (None, 56, 56, 32)           4096      ['block2b_expand_activation[0]\n",
      " 2D)                                                                [0]']                         \n",
      "                                                                                                  \n",
      " block2b_project_bn (BatchN  (None, 56, 56, 32)           128       ['block2b_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block2b_drop (Dropout)      (None, 56, 56, 32)           0         ['block2b_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block2b_add (Add)           (None, 56, 56, 32)           0         ['block2b_drop[0][0]',        \n",
      "                                                                     'block2a_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block2c_expand_conv (Conv2  (None, 56, 56, 128)          36864     ['block2b_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block2c_expand_bn (BatchNo  (None, 56, 56, 128)          512       ['block2c_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block2c_expand_activation   (None, 56, 56, 128)          0         ['block2c_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block2c_project_conv (Conv  (None, 56, 56, 32)           4096      ['block2c_expand_activation[0]\n",
      " 2D)                                                                [0]']                         \n",
      "                                                                                                  \n",
      " block2c_project_bn (BatchN  (None, 56, 56, 32)           128       ['block2c_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block2c_drop (Dropout)      (None, 56, 56, 32)           0         ['block2c_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block2c_add (Add)           (None, 56, 56, 32)           0         ['block2c_drop[0][0]',        \n",
      "                                                                     'block2b_add[0][0]']         \n",
      "                                                                                                  \n",
      " block3a_expand_conv (Conv2  (None, 28, 28, 128)          36864     ['block2c_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block3a_expand_bn (BatchNo  (None, 28, 28, 128)          512       ['block3a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block3a_expand_activation   (None, 28, 28, 128)          0         ['block3a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block3a_project_conv (Conv  (None, 28, 28, 56)           7168      ['block3a_expand_activation[0]\n",
      " 2D)                                                                [0]']                         \n",
      "                                                                                                  \n",
      " block3a_project_bn (BatchN  (None, 28, 28, 56)           224       ['block3a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block3b_expand_conv (Conv2  (None, 28, 28, 224)          112896    ['block3a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block3b_expand_bn (BatchNo  (None, 28, 28, 224)          896       ['block3b_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block3b_expand_activation   (None, 28, 28, 224)          0         ['block3b_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block3b_project_conv (Conv  (None, 28, 28, 56)           12544     ['block3b_expand_activation[0]\n",
      " 2D)                                                                [0]']                         \n",
      "                                                                                                  \n",
      " block3b_project_bn (BatchN  (None, 28, 28, 56)           224       ['block3b_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block3b_drop (Dropout)      (None, 28, 28, 56)           0         ['block3b_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block3b_add (Add)           (None, 28, 28, 56)           0         ['block3b_drop[0][0]',        \n",
      "                                                                     'block3a_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block3c_expand_conv (Conv2  (None, 28, 28, 224)          112896    ['block3b_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block3c_expand_bn (BatchNo  (None, 28, 28, 224)          896       ['block3c_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block3c_expand_activation   (None, 28, 28, 224)          0         ['block3c_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block3c_project_conv (Conv  (None, 28, 28, 56)           12544     ['block3c_expand_activation[0]\n",
      " 2D)                                                                [0]']                         \n",
      "                                                                                                  \n",
      " block3c_project_bn (BatchN  (None, 28, 28, 56)           224       ['block3c_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block3c_drop (Dropout)      (None, 28, 28, 56)           0         ['block3c_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block3c_add (Add)           (None, 28, 28, 56)           0         ['block3c_drop[0][0]',        \n",
      "                                                                     'block3b_add[0][0]']         \n",
      "                                                                                                  \n",
      " block4a_expand_conv (Conv2  (None, 28, 28, 224)          12544     ['block3c_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block4a_expand_bn (BatchNo  (None, 28, 28, 224)          896       ['block4a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block4a_expand_activation   (None, 28, 28, 224)          0         ['block4a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block4a_dwconv2 (Depthwise  (None, 14, 14, 224)          2016      ['block4a_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block4a_bn (BatchNormaliza  (None, 14, 14, 224)          896       ['block4a_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4a_activation (Activa  (None, 14, 14, 224)          0         ['block4a_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4a_se_squeeze (Global  (None, 224)                  0         ['block4a_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block4a_se_reshape (Reshap  (None, 1, 1, 224)            0         ['block4a_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block4a_se_reduce (Conv2D)  (None, 1, 1, 14)             3150      ['block4a_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block4a_se_expand (Conv2D)  (None, 1, 1, 224)            3360      ['block4a_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block4a_se_excite (Multipl  (None, 14, 14, 224)          0         ['block4a_activation[0][0]',  \n",
      " y)                                                                  'block4a_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block4a_project_conv (Conv  (None, 14, 14, 104)          23296     ['block4a_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block4a_project_bn (BatchN  (None, 14, 14, 104)          416       ['block4a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block4b_expand_conv (Conv2  (None, 14, 14, 416)          43264     ['block4a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block4b_expand_bn (BatchNo  (None, 14, 14, 416)          1664      ['block4b_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block4b_expand_activation   (None, 14, 14, 416)          0         ['block4b_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block4b_dwconv2 (Depthwise  (None, 14, 14, 416)          3744      ['block4b_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block4b_bn (BatchNormaliza  (None, 14, 14, 416)          1664      ['block4b_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4b_activation (Activa  (None, 14, 14, 416)          0         ['block4b_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4b_se_squeeze (Global  (None, 416)                  0         ['block4b_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block4b_se_reshape (Reshap  (None, 1, 1, 416)            0         ['block4b_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block4b_se_reduce (Conv2D)  (None, 1, 1, 26)             10842     ['block4b_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block4b_se_expand (Conv2D)  (None, 1, 1, 416)            11232     ['block4b_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block4b_se_excite (Multipl  (None, 14, 14, 416)          0         ['block4b_activation[0][0]',  \n",
      " y)                                                                  'block4b_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block4b_project_conv (Conv  (None, 14, 14, 104)          43264     ['block4b_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block4b_project_bn (BatchN  (None, 14, 14, 104)          416       ['block4b_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block4b_drop (Dropout)      (None, 14, 14, 104)          0         ['block4b_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block4b_add (Add)           (None, 14, 14, 104)          0         ['block4b_drop[0][0]',        \n",
      "                                                                     'block4a_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block4c_expand_conv (Conv2  (None, 14, 14, 416)          43264     ['block4b_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block4c_expand_bn (BatchNo  (None, 14, 14, 416)          1664      ['block4c_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block4c_expand_activation   (None, 14, 14, 416)          0         ['block4c_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block4c_dwconv2 (Depthwise  (None, 14, 14, 416)          3744      ['block4c_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block4c_bn (BatchNormaliza  (None, 14, 14, 416)          1664      ['block4c_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4c_activation (Activa  (None, 14, 14, 416)          0         ['block4c_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4c_se_squeeze (Global  (None, 416)                  0         ['block4c_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block4c_se_reshape (Reshap  (None, 1, 1, 416)            0         ['block4c_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block4c_se_reduce (Conv2D)  (None, 1, 1, 26)             10842     ['block4c_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block4c_se_expand (Conv2D)  (None, 1, 1, 416)            11232     ['block4c_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block4c_se_excite (Multipl  (None, 14, 14, 416)          0         ['block4c_activation[0][0]',  \n",
      " y)                                                                  'block4c_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block4c_project_conv (Conv  (None, 14, 14, 104)          43264     ['block4c_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block4c_project_bn (BatchN  (None, 14, 14, 104)          416       ['block4c_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block4c_drop (Dropout)      (None, 14, 14, 104)          0         ['block4c_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block4c_add (Add)           (None, 14, 14, 104)          0         ['block4c_drop[0][0]',        \n",
      "                                                                     'block4b_add[0][0]']         \n",
      "                                                                                                  \n",
      " block4d_expand_conv (Conv2  (None, 14, 14, 416)          43264     ['block4c_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block4d_expand_bn (BatchNo  (None, 14, 14, 416)          1664      ['block4d_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block4d_expand_activation   (None, 14, 14, 416)          0         ['block4d_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block4d_dwconv2 (Depthwise  (None, 14, 14, 416)          3744      ['block4d_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block4d_bn (BatchNormaliza  (None, 14, 14, 416)          1664      ['block4d_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4d_activation (Activa  (None, 14, 14, 416)          0         ['block4d_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4d_se_squeeze (Global  (None, 416)                  0         ['block4d_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block4d_se_reshape (Reshap  (None, 1, 1, 416)            0         ['block4d_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block4d_se_reduce (Conv2D)  (None, 1, 1, 26)             10842     ['block4d_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block4d_se_expand (Conv2D)  (None, 1, 1, 416)            11232     ['block4d_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block4d_se_excite (Multipl  (None, 14, 14, 416)          0         ['block4d_activation[0][0]',  \n",
      " y)                                                                  'block4d_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block4d_project_conv (Conv  (None, 14, 14, 104)          43264     ['block4d_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block4d_project_bn (BatchN  (None, 14, 14, 104)          416       ['block4d_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block4d_drop (Dropout)      (None, 14, 14, 104)          0         ['block4d_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block4d_add (Add)           (None, 14, 14, 104)          0         ['block4d_drop[0][0]',        \n",
      "                                                                     'block4c_add[0][0]']         \n",
      "                                                                                                  \n",
      " block5a_expand_conv (Conv2  (None, 14, 14, 624)          64896     ['block4d_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block5a_expand_bn (BatchNo  (None, 14, 14, 624)          2496      ['block5a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block5a_expand_activation   (None, 14, 14, 624)          0         ['block5a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block5a_dwconv2 (Depthwise  (None, 14, 14, 624)          5616      ['block5a_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block5a_bn (BatchNormaliza  (None, 14, 14, 624)          2496      ['block5a_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5a_activation (Activa  (None, 14, 14, 624)          0         ['block5a_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5a_se_squeeze (Global  (None, 624)                  0         ['block5a_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block5a_se_reshape (Reshap  (None, 1, 1, 624)            0         ['block5a_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block5a_se_reduce (Conv2D)  (None, 1, 1, 26)             16250     ['block5a_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block5a_se_expand (Conv2D)  (None, 1, 1, 624)            16848     ['block5a_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block5a_se_excite (Multipl  (None, 14, 14, 624)          0         ['block5a_activation[0][0]',  \n",
      " y)                                                                  'block5a_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block5a_project_conv (Conv  (None, 14, 14, 120)          74880     ['block5a_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5a_project_bn (BatchN  (None, 14, 14, 120)          480       ['block5a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block5b_expand_conv (Conv2  (None, 14, 14, 720)          86400     ['block5a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block5b_expand_bn (BatchNo  (None, 14, 14, 720)          2880      ['block5b_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block5b_expand_activation   (None, 14, 14, 720)          0         ['block5b_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block5b_dwconv2 (Depthwise  (None, 14, 14, 720)          6480      ['block5b_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block5b_bn (BatchNormaliza  (None, 14, 14, 720)          2880      ['block5b_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5b_activation (Activa  (None, 14, 14, 720)          0         ['block5b_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5b_se_squeeze (Global  (None, 720)                  0         ['block5b_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block5b_se_reshape (Reshap  (None, 1, 1, 720)            0         ['block5b_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block5b_se_reduce (Conv2D)  (None, 1, 1, 30)             21630     ['block5b_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block5b_se_expand (Conv2D)  (None, 1, 1, 720)            22320     ['block5b_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block5b_se_excite (Multipl  (None, 14, 14, 720)          0         ['block5b_activation[0][0]',  \n",
      " y)                                                                  'block5b_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block5b_project_conv (Conv  (None, 14, 14, 120)          86400     ['block5b_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5b_project_bn (BatchN  (None, 14, 14, 120)          480       ['block5b_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block5b_drop (Dropout)      (None, 14, 14, 120)          0         ['block5b_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block5b_add (Add)           (None, 14, 14, 120)          0         ['block5b_drop[0][0]',        \n",
      "                                                                     'block5a_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block5c_expand_conv (Conv2  (None, 14, 14, 720)          86400     ['block5b_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block5c_expand_bn (BatchNo  (None, 14, 14, 720)          2880      ['block5c_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block5c_expand_activation   (None, 14, 14, 720)          0         ['block5c_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block5c_dwconv2 (Depthwise  (None, 14, 14, 720)          6480      ['block5c_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block5c_bn (BatchNormaliza  (None, 14, 14, 720)          2880      ['block5c_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5c_activation (Activa  (None, 14, 14, 720)          0         ['block5c_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5c_se_squeeze (Global  (None, 720)                  0         ['block5c_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block5c_se_reshape (Reshap  (None, 1, 1, 720)            0         ['block5c_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block5c_se_reduce (Conv2D)  (None, 1, 1, 30)             21630     ['block5c_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block5c_se_expand (Conv2D)  (None, 1, 1, 720)            22320     ['block5c_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block5c_se_excite (Multipl  (None, 14, 14, 720)          0         ['block5c_activation[0][0]',  \n",
      " y)                                                                  'block5c_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block5c_project_conv (Conv  (None, 14, 14, 120)          86400     ['block5c_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5c_project_bn (BatchN  (None, 14, 14, 120)          480       ['block5c_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block5c_drop (Dropout)      (None, 14, 14, 120)          0         ['block5c_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block5c_add (Add)           (None, 14, 14, 120)          0         ['block5c_drop[0][0]',        \n",
      "                                                                     'block5b_add[0][0]']         \n",
      "                                                                                                  \n",
      " block5d_expand_conv (Conv2  (None, 14, 14, 720)          86400     ['block5c_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block5d_expand_bn (BatchNo  (None, 14, 14, 720)          2880      ['block5d_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block5d_expand_activation   (None, 14, 14, 720)          0         ['block5d_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block5d_dwconv2 (Depthwise  (None, 14, 14, 720)          6480      ['block5d_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block5d_bn (BatchNormaliza  (None, 14, 14, 720)          2880      ['block5d_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5d_activation (Activa  (None, 14, 14, 720)          0         ['block5d_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5d_se_squeeze (Global  (None, 720)                  0         ['block5d_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block5d_se_reshape (Reshap  (None, 1, 1, 720)            0         ['block5d_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block5d_se_reduce (Conv2D)  (None, 1, 1, 30)             21630     ['block5d_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block5d_se_expand (Conv2D)  (None, 1, 1, 720)            22320     ['block5d_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block5d_se_excite (Multipl  (None, 14, 14, 720)          0         ['block5d_activation[0][0]',  \n",
      " y)                                                                  'block5d_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block5d_project_conv (Conv  (None, 14, 14, 120)          86400     ['block5d_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5d_project_bn (BatchN  (None, 14, 14, 120)          480       ['block5d_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block5d_drop (Dropout)      (None, 14, 14, 120)          0         ['block5d_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block5d_add (Add)           (None, 14, 14, 120)          0         ['block5d_drop[0][0]',        \n",
      "                                                                     'block5c_add[0][0]']         \n",
      "                                                                                                  \n",
      " block5e_expand_conv (Conv2  (None, 14, 14, 720)          86400     ['block5d_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block5e_expand_bn (BatchNo  (None, 14, 14, 720)          2880      ['block5e_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block5e_expand_activation   (None, 14, 14, 720)          0         ['block5e_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block5e_dwconv2 (Depthwise  (None, 14, 14, 720)          6480      ['block5e_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block5e_bn (BatchNormaliza  (None, 14, 14, 720)          2880      ['block5e_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5e_activation (Activa  (None, 14, 14, 720)          0         ['block5e_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5e_se_squeeze (Global  (None, 720)                  0         ['block5e_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block5e_se_reshape (Reshap  (None, 1, 1, 720)            0         ['block5e_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block5e_se_reduce (Conv2D)  (None, 1, 1, 30)             21630     ['block5e_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block5e_se_expand (Conv2D)  (None, 1, 1, 720)            22320     ['block5e_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block5e_se_excite (Multipl  (None, 14, 14, 720)          0         ['block5e_activation[0][0]',  \n",
      " y)                                                                  'block5e_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block5e_project_conv (Conv  (None, 14, 14, 120)          86400     ['block5e_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5e_project_bn (BatchN  (None, 14, 14, 120)          480       ['block5e_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block5e_drop (Dropout)      (None, 14, 14, 120)          0         ['block5e_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block5e_add (Add)           (None, 14, 14, 120)          0         ['block5e_drop[0][0]',        \n",
      "                                                                     'block5d_add[0][0]']         \n",
      "                                                                                                  \n",
      " block5f_expand_conv (Conv2  (None, 14, 14, 720)          86400     ['block5e_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block5f_expand_bn (BatchNo  (None, 14, 14, 720)          2880      ['block5f_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block5f_expand_activation   (None, 14, 14, 720)          0         ['block5f_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block5f_dwconv2 (Depthwise  (None, 14, 14, 720)          6480      ['block5f_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block5f_bn (BatchNormaliza  (None, 14, 14, 720)          2880      ['block5f_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5f_activation (Activa  (None, 14, 14, 720)          0         ['block5f_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5f_se_squeeze (Global  (None, 720)                  0         ['block5f_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block5f_se_reshape (Reshap  (None, 1, 1, 720)            0         ['block5f_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block5f_se_reduce (Conv2D)  (None, 1, 1, 30)             21630     ['block5f_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block5f_se_expand (Conv2D)  (None, 1, 1, 720)            22320     ['block5f_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block5f_se_excite (Multipl  (None, 14, 14, 720)          0         ['block5f_activation[0][0]',  \n",
      " y)                                                                  'block5f_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block5f_project_conv (Conv  (None, 14, 14, 120)          86400     ['block5f_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5f_project_bn (BatchN  (None, 14, 14, 120)          480       ['block5f_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block5f_drop (Dropout)      (None, 14, 14, 120)          0         ['block5f_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block5f_add (Add)           (None, 14, 14, 120)          0         ['block5f_drop[0][0]',        \n",
      "                                                                     'block5e_add[0][0]']         \n",
      "                                                                                                  \n",
      " block6a_expand_conv (Conv2  (None, 14, 14, 720)          86400     ['block5f_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6a_expand_bn (BatchNo  (None, 14, 14, 720)          2880      ['block6a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6a_expand_activation   (None, 14, 14, 720)          0         ['block6a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6a_dwconv2 (Depthwise  (None, 7, 7, 720)            6480      ['block6a_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block6a_bn (BatchNormaliza  (None, 7, 7, 720)            2880      ['block6a_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6a_activation (Activa  (None, 7, 7, 720)            0         ['block6a_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6a_se_squeeze (Global  (None, 720)                  0         ['block6a_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6a_se_reshape (Reshap  (None, 1, 1, 720)            0         ['block6a_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6a_se_reduce (Conv2D)  (None, 1, 1, 30)             21630     ['block6a_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6a_se_expand (Conv2D)  (None, 1, 1, 720)            22320     ['block6a_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6a_se_excite (Multipl  (None, 7, 7, 720)            0         ['block6a_activation[0][0]',  \n",
      " y)                                                                  'block6a_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6a_project_conv (Conv  (None, 7, 7, 208)            149760    ['block6a_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6a_project_bn (BatchN  (None, 7, 7, 208)            832       ['block6a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6b_expand_conv (Conv2  (None, 7, 7, 1248)           259584    ['block6a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6b_expand_bn (BatchNo  (None, 7, 7, 1248)           4992      ['block6b_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6b_expand_activation   (None, 7, 7, 1248)           0         ['block6b_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6b_dwconv2 (Depthwise  (None, 7, 7, 1248)           11232     ['block6b_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block6b_bn (BatchNormaliza  (None, 7, 7, 1248)           4992      ['block6b_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6b_activation (Activa  (None, 7, 7, 1248)           0         ['block6b_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6b_se_squeeze (Global  (None, 1248)                 0         ['block6b_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6b_se_reshape (Reshap  (None, 1, 1, 1248)           0         ['block6b_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6b_se_reduce (Conv2D)  (None, 1, 1, 52)             64948     ['block6b_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6b_se_expand (Conv2D)  (None, 1, 1, 1248)           66144     ['block6b_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6b_se_excite (Multipl  (None, 7, 7, 1248)           0         ['block6b_activation[0][0]',  \n",
      " y)                                                                  'block6b_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6b_project_conv (Conv  (None, 7, 7, 208)            259584    ['block6b_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6b_project_bn (BatchN  (None, 7, 7, 208)            832       ['block6b_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6b_drop (Dropout)      (None, 7, 7, 208)            0         ['block6b_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6b_add (Add)           (None, 7, 7, 208)            0         ['block6b_drop[0][0]',        \n",
      "                                                                     'block6a_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6c_expand_conv (Conv2  (None, 7, 7, 1248)           259584    ['block6b_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6c_expand_bn (BatchNo  (None, 7, 7, 1248)           4992      ['block6c_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6c_expand_activation   (None, 7, 7, 1248)           0         ['block6c_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6c_dwconv2 (Depthwise  (None, 7, 7, 1248)           11232     ['block6c_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block6c_bn (BatchNormaliza  (None, 7, 7, 1248)           4992      ['block6c_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6c_activation (Activa  (None, 7, 7, 1248)           0         ['block6c_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6c_se_squeeze (Global  (None, 1248)                 0         ['block6c_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6c_se_reshape (Reshap  (None, 1, 1, 1248)           0         ['block6c_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6c_se_reduce (Conv2D)  (None, 1, 1, 52)             64948     ['block6c_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6c_se_expand (Conv2D)  (None, 1, 1, 1248)           66144     ['block6c_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6c_se_excite (Multipl  (None, 7, 7, 1248)           0         ['block6c_activation[0][0]',  \n",
      " y)                                                                  'block6c_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6c_project_conv (Conv  (None, 7, 7, 208)            259584    ['block6c_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6c_project_bn (BatchN  (None, 7, 7, 208)            832       ['block6c_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6c_drop (Dropout)      (None, 7, 7, 208)            0         ['block6c_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6c_add (Add)           (None, 7, 7, 208)            0         ['block6c_drop[0][0]',        \n",
      "                                                                     'block6b_add[0][0]']         \n",
      "                                                                                                  \n",
      " block6d_expand_conv (Conv2  (None, 7, 7, 1248)           259584    ['block6c_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6d_expand_bn (BatchNo  (None, 7, 7, 1248)           4992      ['block6d_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6d_expand_activation   (None, 7, 7, 1248)           0         ['block6d_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6d_dwconv2 (Depthwise  (None, 7, 7, 1248)           11232     ['block6d_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block6d_bn (BatchNormaliza  (None, 7, 7, 1248)           4992      ['block6d_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6d_activation (Activa  (None, 7, 7, 1248)           0         ['block6d_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6d_se_squeeze (Global  (None, 1248)                 0         ['block6d_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6d_se_reshape (Reshap  (None, 1, 1, 1248)           0         ['block6d_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6d_se_reduce (Conv2D)  (None, 1, 1, 52)             64948     ['block6d_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6d_se_expand (Conv2D)  (None, 1, 1, 1248)           66144     ['block6d_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6d_se_excite (Multipl  (None, 7, 7, 1248)           0         ['block6d_activation[0][0]',  \n",
      " y)                                                                  'block6d_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6d_project_conv (Conv  (None, 7, 7, 208)            259584    ['block6d_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6d_project_bn (BatchN  (None, 7, 7, 208)            832       ['block6d_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6d_drop (Dropout)      (None, 7, 7, 208)            0         ['block6d_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6d_add (Add)           (None, 7, 7, 208)            0         ['block6d_drop[0][0]',        \n",
      "                                                                     'block6c_add[0][0]']         \n",
      "                                                                                                  \n",
      " block6e_expand_conv (Conv2  (None, 7, 7, 1248)           259584    ['block6d_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6e_expand_bn (BatchNo  (None, 7, 7, 1248)           4992      ['block6e_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6e_expand_activation   (None, 7, 7, 1248)           0         ['block6e_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6e_dwconv2 (Depthwise  (None, 7, 7, 1248)           11232     ['block6e_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block6e_bn (BatchNormaliza  (None, 7, 7, 1248)           4992      ['block6e_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6e_activation (Activa  (None, 7, 7, 1248)           0         ['block6e_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6e_se_squeeze (Global  (None, 1248)                 0         ['block6e_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6e_se_reshape (Reshap  (None, 1, 1, 1248)           0         ['block6e_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6e_se_reduce (Conv2D)  (None, 1, 1, 52)             64948     ['block6e_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6e_se_expand (Conv2D)  (None, 1, 1, 1248)           66144     ['block6e_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6e_se_excite (Multipl  (None, 7, 7, 1248)           0         ['block6e_activation[0][0]',  \n",
      " y)                                                                  'block6e_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6e_project_conv (Conv  (None, 7, 7, 208)            259584    ['block6e_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6e_project_bn (BatchN  (None, 7, 7, 208)            832       ['block6e_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6e_drop (Dropout)      (None, 7, 7, 208)            0         ['block6e_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6e_add (Add)           (None, 7, 7, 208)            0         ['block6e_drop[0][0]',        \n",
      "                                                                     'block6d_add[0][0]']         \n",
      "                                                                                                  \n",
      " block6f_expand_conv (Conv2  (None, 7, 7, 1248)           259584    ['block6e_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6f_expand_bn (BatchNo  (None, 7, 7, 1248)           4992      ['block6f_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6f_expand_activation   (None, 7, 7, 1248)           0         ['block6f_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6f_dwconv2 (Depthwise  (None, 7, 7, 1248)           11232     ['block6f_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block6f_bn (BatchNormaliza  (None, 7, 7, 1248)           4992      ['block6f_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6f_activation (Activa  (None, 7, 7, 1248)           0         ['block6f_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6f_se_squeeze (Global  (None, 1248)                 0         ['block6f_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6f_se_reshape (Reshap  (None, 1, 1, 1248)           0         ['block6f_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6f_se_reduce (Conv2D)  (None, 1, 1, 52)             64948     ['block6f_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6f_se_expand (Conv2D)  (None, 1, 1, 1248)           66144     ['block6f_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6f_se_excite (Multipl  (None, 7, 7, 1248)           0         ['block6f_activation[0][0]',  \n",
      " y)                                                                  'block6f_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6f_project_conv (Conv  (None, 7, 7, 208)            259584    ['block6f_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6f_project_bn (BatchN  (None, 7, 7, 208)            832       ['block6f_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6f_drop (Dropout)      (None, 7, 7, 208)            0         ['block6f_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6f_add (Add)           (None, 7, 7, 208)            0         ['block6f_drop[0][0]',        \n",
      "                                                                     'block6e_add[0][0]']         \n",
      "                                                                                                  \n",
      " block6g_expand_conv (Conv2  (None, 7, 7, 1248)           259584    ['block6f_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6g_expand_bn (BatchNo  (None, 7, 7, 1248)           4992      ['block6g_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6g_expand_activation   (None, 7, 7, 1248)           0         ['block6g_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6g_dwconv2 (Depthwise  (None, 7, 7, 1248)           11232     ['block6g_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block6g_bn (BatchNormaliza  (None, 7, 7, 1248)           4992      ['block6g_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6g_activation (Activa  (None, 7, 7, 1248)           0         ['block6g_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6g_se_squeeze (Global  (None, 1248)                 0         ['block6g_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6g_se_reshape (Reshap  (None, 1, 1, 1248)           0         ['block6g_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6g_se_reduce (Conv2D)  (None, 1, 1, 52)             64948     ['block6g_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6g_se_expand (Conv2D)  (None, 1, 1, 1248)           66144     ['block6g_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6g_se_excite (Multipl  (None, 7, 7, 1248)           0         ['block6g_activation[0][0]',  \n",
      " y)                                                                  'block6g_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6g_project_conv (Conv  (None, 7, 7, 208)            259584    ['block6g_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6g_project_bn (BatchN  (None, 7, 7, 208)            832       ['block6g_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6g_drop (Dropout)      (None, 7, 7, 208)            0         ['block6g_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6g_add (Add)           (None, 7, 7, 208)            0         ['block6g_drop[0][0]',        \n",
      "                                                                     'block6f_add[0][0]']         \n",
      "                                                                                                  \n",
      " block6h_expand_conv (Conv2  (None, 7, 7, 1248)           259584    ['block6g_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6h_expand_bn (BatchNo  (None, 7, 7, 1248)           4992      ['block6h_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6h_expand_activation   (None, 7, 7, 1248)           0         ['block6h_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6h_dwconv2 (Depthwise  (None, 7, 7, 1248)           11232     ['block6h_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block6h_bn (BatchNormaliza  (None, 7, 7, 1248)           4992      ['block6h_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6h_activation (Activa  (None, 7, 7, 1248)           0         ['block6h_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6h_se_squeeze (Global  (None, 1248)                 0         ['block6h_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6h_se_reshape (Reshap  (None, 1, 1, 1248)           0         ['block6h_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6h_se_reduce (Conv2D)  (None, 1, 1, 52)             64948     ['block6h_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6h_se_expand (Conv2D)  (None, 1, 1, 1248)           66144     ['block6h_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6h_se_excite (Multipl  (None, 7, 7, 1248)           0         ['block6h_activation[0][0]',  \n",
      " y)                                                                  'block6h_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6h_project_conv (Conv  (None, 7, 7, 208)            259584    ['block6h_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6h_project_bn (BatchN  (None, 7, 7, 208)            832       ['block6h_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6h_drop (Dropout)      (None, 7, 7, 208)            0         ['block6h_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6h_add (Add)           (None, 7, 7, 208)            0         ['block6h_drop[0][0]',        \n",
      "                                                                     'block6g_add[0][0]']         \n",
      "                                                                                                  \n",
      " block6i_expand_conv (Conv2  (None, 7, 7, 1248)           259584    ['block6h_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6i_expand_bn (BatchNo  (None, 7, 7, 1248)           4992      ['block6i_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6i_expand_activation   (None, 7, 7, 1248)           0         ['block6i_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6i_dwconv2 (Depthwise  (None, 7, 7, 1248)           11232     ['block6i_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block6i_bn (BatchNormaliza  (None, 7, 7, 1248)           4992      ['block6i_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6i_activation (Activa  (None, 7, 7, 1248)           0         ['block6i_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6i_se_squeeze (Global  (None, 1248)                 0         ['block6i_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6i_se_reshape (Reshap  (None, 1, 1, 1248)           0         ['block6i_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6i_se_reduce (Conv2D)  (None, 1, 1, 52)             64948     ['block6i_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6i_se_expand (Conv2D)  (None, 1, 1, 1248)           66144     ['block6i_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6i_se_excite (Multipl  (None, 7, 7, 1248)           0         ['block6i_activation[0][0]',  \n",
      " y)                                                                  'block6i_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6i_project_conv (Conv  (None, 7, 7, 208)            259584    ['block6i_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6i_project_bn (BatchN  (None, 7, 7, 208)            832       ['block6i_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6i_drop (Dropout)      (None, 7, 7, 208)            0         ['block6i_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6i_add (Add)           (None, 7, 7, 208)            0         ['block6i_drop[0][0]',        \n",
      "                                                                     'block6h_add[0][0]']         \n",
      "                                                                                                  \n",
      " block6j_expand_conv (Conv2  (None, 7, 7, 1248)           259584    ['block6i_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6j_expand_bn (BatchNo  (None, 7, 7, 1248)           4992      ['block6j_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6j_expand_activation   (None, 7, 7, 1248)           0         ['block6j_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6j_dwconv2 (Depthwise  (None, 7, 7, 1248)           11232     ['block6j_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block6j_bn (BatchNormaliza  (None, 7, 7, 1248)           4992      ['block6j_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6j_activation (Activa  (None, 7, 7, 1248)           0         ['block6j_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6j_se_squeeze (Global  (None, 1248)                 0         ['block6j_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6j_se_reshape (Reshap  (None, 1, 1, 1248)           0         ['block6j_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6j_se_reduce (Conv2D)  (None, 1, 1, 52)             64948     ['block6j_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6j_se_expand (Conv2D)  (None, 1, 1, 1248)           66144     ['block6j_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6j_se_excite (Multipl  (None, 7, 7, 1248)           0         ['block6j_activation[0][0]',  \n",
      " y)                                                                  'block6j_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6j_project_conv (Conv  (None, 7, 7, 208)            259584    ['block6j_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6j_project_bn (BatchN  (None, 7, 7, 208)            832       ['block6j_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6j_drop (Dropout)      (None, 7, 7, 208)            0         ['block6j_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6j_add (Add)           (None, 7, 7, 208)            0         ['block6j_drop[0][0]',        \n",
      "                                                                     'block6i_add[0][0]']         \n",
      "                                                                                                  \n",
      " top_conv (Conv2D)           (None, 7, 7, 1408)           292864    ['block6j_add[0][0]']         \n",
      "                                                                                                  \n",
      " top_bn (BatchNormalization  (None, 7, 7, 1408)           5632      ['top_conv[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " top_activation (Activation  (None, 7, 7, 1408)           0         ['top_bn[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8769374 (33.45 MB)\n",
      "Trainable params: 8687086 (33.14 MB)\n",
      "Non-trainable params: 82288 (321.44 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.applications import EfficientNetV2B2\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D,Conv2D, Flatten, BatchNormalization, Dense, Dropout\n",
    "from tensorflow.keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
    "base_model = EfficientNetV2B2(\n",
    "                    input_shape=(224, 224, 3),\n",
    "                    weights='imagenet',\n",
    "                    include_top=False,\n",
    "                    include_preprocessing=True,\n",
    "                    )\n",
    "# Freeze the first 10 layers\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cef2159-1034-43a8-9803-d02c6cf10158",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers[:10]:\n",
    "    layer.trainable = False\n",
    "x = base_model.output\n",
    "x = Conv2D(256,(3,3),activation='relu')(x)\n",
    "x = Conv2D(128,(3,3),activation='relu')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu',kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.01))(x)\n",
    "x = Dropout(0.4)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model1 = Model(inputs=base_model.inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c5a987a-b590-4e3a-8776-1fde5e2e007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf\n",
    "checkpoint = ModelCheckpoint(\"radha_Beta.h5\",\n",
    "                             monitor='val_loss',\n",
    "                             mode='min',\n",
    "                             save_best_only=True,verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss',\n",
    "                          min_delta=0,\n",
    "                          patience=3,\n",
    "                          verbose=1,\n",
    "                          restore_best_weights=True)\n",
    "\n",
    "callbacks=[checkpoint,earlystop]\n",
    "\n",
    "epochs=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aeca5ab-6bb8-4f27-b7b1-cdd7cf2fe85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-13 13:43:03.987113: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/block1b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2024-01-13 13:43:06.081237: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:06.082402: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:225] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2024-01-13 13:43:06.082411: W external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:228] Used ptxas at ptxas\n",
      "2024-01-13 13:43:06.082445: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:06.183988: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:06.184321: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:06.184641: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:06.185141: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:06.185414: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:06.185577: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:06.185852: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:06.186349: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:06.187112: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:06.187751: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:06.187774: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:06.187955: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:06.188332: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:06.189259: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:06.189274: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:06.189358: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:06.485236: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-01-13 13:43:06.637343: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:06.638746: W external/local_xla/xla/stream_executor/gpu/redzone_allocator.cc:322] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2024-01-13 13:43:06.942337: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:06.943740: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:07.448001: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:07.448034: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:07.449147: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:07.449237: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:07.449448: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:07.449508: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:07.450427: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:07.450486: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:07.450551: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:07.450628: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:07.451915: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:07.451939: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:07.452696: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:07.453453: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:07.453897: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:07.454352: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:07.454677: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:07.455543: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:08.378163: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:08.379679: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:08.477780: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:08.478037: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:08.478796: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:08.479376: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:08.479429: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:08.479471: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:08.479498: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:08.480326: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:08.481119: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:08.481160: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:08.482118: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:08.482353: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:08.482395: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:08.483258: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:08.483580: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:08.483622: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:08.648420: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f17f0bac4a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-13 13:43:08.648443: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A4000, Compute Capability 8.6\n",
      "2024-01-13 13:43:08.657072: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-13 13:43:08.658256: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:08.659653: W tensorflow/compiler/mlir/tools/kernel_gen/transforms/gpu_kernel_to_blob_pass.cc:191] Failed to compile generated PTX with ptxas. Falling back to compilation by driver.\n",
      "2024-01-13 13:43:08.690965: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:08.693014: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:408] Couldn't read CUDA driver version.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1705133588.713003    6339 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-01-13 13:43:08.805015: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:08.892447: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:08.958059: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:09.016703: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:09.408454: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:09.616940: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:09.655586: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:09.727919: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:09.835701: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:09.924961: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:09.976082: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:10.053230: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:10.150219: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:10.291511: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:14.368463: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:14.456300: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:14.534140: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:14.646022: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:14.785701: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:14.932728: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:14.975439: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:17.265000: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:17.308235: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:17.378525: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:17.469624: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:17.616414: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:17.863042: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:17.966393: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:18.048122: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:18.094978: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:18.313639: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:19.567953: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:19.635852: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:19.691694: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:19.795459: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:19.932440: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:20.029156: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:20.069850: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:20.364400: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:21.110744: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/134 [..............................] - ETA: 1:11:11 - loss: 5.8038 - accuracy: 0.1250 - auc: 0.4402"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-13 13:43:23.157068: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-01-13 13:43:23.248259: E external/local_xla/xla/stream_executor/gpu/asm_compiler.cc:115] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - ETA: 0s - loss: 4.4967 - accuracy: 0.6730 - auc: 0.9092\n",
      "Epoch 1: val_loss improved from inf to 3.70780, saving model to radha_Beta.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin1/miniconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 98s 493ms/step - loss: 4.4967 - accuracy: 0.6730 - auc: 0.9092 - val_loss: 3.7078 - val_accuracy: 0.8438 - val_auc: 0.9750\n",
      "Epoch 2/20\n",
      "134/134 [==============================] - ETA: 0s - loss: 3.3936 - accuracy: 0.8461 - auc: 0.9737\n",
      "Epoch 2: val_loss improved from 3.70780 to 2.98909, saving model to radha_Beta.h5\n",
      "134/134 [==============================] - 60s 444ms/step - loss: 3.3936 - accuracy: 0.8461 - auc: 0.9737 - val_loss: 2.9891 - val_accuracy: 0.8574 - val_auc: 0.9840\n",
      "Epoch 3/20\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.6712 - accuracy: 0.8944 - auc: 0.9865\n",
      "Epoch 3: val_loss improved from 2.98909 to 2.40135, saving model to radha_Beta.h5\n",
      "134/134 [==============================] - 59s 441ms/step - loss: 2.6712 - accuracy: 0.8944 - auc: 0.9865 - val_loss: 2.4014 - val_accuracy: 0.9023 - val_auc: 0.9865\n",
      "Epoch 4/20\n",
      "134/134 [==============================] - ETA: 0s - loss: 2.1379 - accuracy: 0.9150 - auc: 0.9910\n",
      "Epoch 4: val_loss improved from 2.40135 to 2.09051, saving model to radha_Beta.h5\n",
      "134/134 [==============================] - 59s 439ms/step - loss: 2.1379 - accuracy: 0.9150 - auc: 0.9910 - val_loss: 2.0905 - val_accuracy: 0.8750 - val_auc: 0.9841\n",
      "Epoch 5/20\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.7265 - accuracy: 0.9330 - auc: 0.9940\n",
      "Epoch 5: val_loss improved from 2.09051 to 1.70946, saving model to radha_Beta.h5\n",
      "134/134 [==============================] - 59s 439ms/step - loss: 1.7265 - accuracy: 0.9330 - auc: 0.9940 - val_loss: 1.7095 - val_accuracy: 0.8945 - val_auc: 0.9879\n",
      "Epoch 6/20\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.4288 - accuracy: 0.9421 - auc: 0.9949\n",
      "Epoch 6: val_loss improved from 1.70946 to 1.47292, saving model to radha_Beta.h5\n",
      "134/134 [==============================] - 59s 440ms/step - loss: 1.4288 - accuracy: 0.9421 - auc: 0.9949 - val_loss: 1.4729 - val_accuracy: 0.9082 - val_auc: 0.9864\n",
      "Epoch 7/20\n",
      "134/134 [==============================] - ETA: 0s - loss: 1.1712 - accuracy: 0.9528 - auc: 0.9968\n",
      "Epoch 7: val_loss improved from 1.47292 to 1.38929, saving model to radha_Beta.h5\n",
      "134/134 [==============================] - 59s 438ms/step - loss: 1.1712 - accuracy: 0.9528 - auc: 0.9968 - val_loss: 1.3893 - val_accuracy: 0.8945 - val_auc: 0.9800\n",
      "Epoch 8/20\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.9679 - accuracy: 0.9645 - auc: 0.9976\n",
      "Epoch 8: val_loss improved from 1.38929 to 1.19433, saving model to radha_Beta.h5\n",
      "134/134 [==============================] - 59s 445ms/step - loss: 0.9679 - accuracy: 0.9645 - auc: 0.9976 - val_loss: 1.1943 - val_accuracy: 0.8965 - val_auc: 0.9786\n",
      "Epoch 9/20\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.8291 - accuracy: 0.9661 - auc: 0.9975\n",
      "Epoch 9: val_loss improved from 1.19433 to 1.07738, saving model to radha_Beta.h5\n",
      "134/134 [==============================] - 59s 441ms/step - loss: 0.8291 - accuracy: 0.9661 - auc: 0.9975 - val_loss: 1.0774 - val_accuracy: 0.9062 - val_auc: 0.9789\n",
      "Epoch 10/20\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.6961 - accuracy: 0.9692 - auc: 0.9980\n",
      "Epoch 10: val_loss improved from 1.07738 to 1.03628, saving model to radha_Beta.h5\n",
      "134/134 [==============================] - 60s 442ms/step - loss: 0.6961 - accuracy: 0.9692 - auc: 0.9980 - val_loss: 1.0363 - val_accuracy: 0.8984 - val_auc: 0.9747\n",
      "Epoch 11/20\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.6041 - accuracy: 0.9738 - auc: 0.9981\n",
      "Epoch 11: val_loss improved from 1.03628 to 0.93591, saving model to radha_Beta.h5\n",
      "134/134 [==============================] - 59s 441ms/step - loss: 0.6041 - accuracy: 0.9738 - auc: 0.9981 - val_loss: 0.9359 - val_accuracy: 0.8965 - val_auc: 0.9789\n",
      "Epoch 12/20\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.5269 - accuracy: 0.9727 - auc: 0.9983\n",
      "Epoch 12: val_loss improved from 0.93591 to 0.90304, saving model to radha_Beta.h5\n",
      "134/134 [==============================] - 59s 439ms/step - loss: 0.5269 - accuracy: 0.9727 - auc: 0.9983 - val_loss: 0.9030 - val_accuracy: 0.9004 - val_auc: 0.9745\n",
      "Epoch 13/20\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.4376 - accuracy: 0.9799 - auc: 0.9987\n",
      "Epoch 13: val_loss did not improve from 0.90304\n",
      "134/134 [==============================] - 58s 434ms/step - loss: 0.4376 - accuracy: 0.9799 - auc: 0.9987 - val_loss: 0.9096 - val_accuracy: 0.8965 - val_auc: 0.9693\n",
      "Epoch 14/20\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3774 - accuracy: 0.9834 - auc: 0.9983\n",
      "Epoch 14: val_loss improved from 0.90304 to 0.85861, saving model to radha_Beta.h5\n",
      "134/134 [==============================] - 60s 447ms/step - loss: 0.3774 - accuracy: 0.9834 - auc: 0.9983 - val_loss: 0.8586 - val_accuracy: 0.9004 - val_auc: 0.9714\n",
      "Epoch 15/20\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.3227 - accuracy: 0.9827 - auc: 0.9989\n",
      "Epoch 15: val_loss improved from 0.85861 to 0.82914, saving model to radha_Beta.h5\n",
      "134/134 [==============================] - 59s 442ms/step - loss: 0.3227 - accuracy: 0.9827 - auc: 0.9989 - val_loss: 0.8291 - val_accuracy: 0.8945 - val_auc: 0.9704\n",
      "Epoch 16/20\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2807 - accuracy: 0.9837 - auc: 0.9988\n",
      "Epoch 16: val_loss improved from 0.82914 to 0.82392, saving model to radha_Beta.h5\n",
      "134/134 [==============================] - 59s 442ms/step - loss: 0.2807 - accuracy: 0.9837 - auc: 0.9988 - val_loss: 0.8239 - val_accuracy: 0.9023 - val_auc: 0.9678\n",
      "Epoch 17/20\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2486 - accuracy: 0.9851 - auc: 0.9992\n",
      "Epoch 17: val_loss improved from 0.82392 to 0.77713, saving model to radha_Beta.h5\n",
      "134/134 [==============================] - 60s 445ms/step - loss: 0.2486 - accuracy: 0.9851 - auc: 0.9992 - val_loss: 0.7771 - val_accuracy: 0.9062 - val_auc: 0.9654\n",
      "Epoch 18/20\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.2177 - accuracy: 0.9872 - auc: 0.9986\n",
      "Epoch 18: val_loss improved from 0.77713 to 0.71592, saving model to radha_Beta.h5\n",
      "134/134 [==============================] - 60s 446ms/step - loss: 0.2177 - accuracy: 0.9872 - auc: 0.9986 - val_loss: 0.7159 - val_accuracy: 0.8984 - val_auc: 0.9695\n",
      "Epoch 19/20\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1855 - accuracy: 0.9886 - auc: 0.9995\n",
      "Epoch 19: val_loss did not improve from 0.71592\n",
      "134/134 [==============================] - 58s 436ms/step - loss: 0.1855 - accuracy: 0.9886 - auc: 0.9995 - val_loss: 0.7649 - val_accuracy: 0.9062 - val_auc: 0.9684\n",
      "Epoch 20/20\n",
      "134/134 [==============================] - ETA: 0s - loss: 0.1719 - accuracy: 0.9867 - auc: 0.9992\n",
      "Epoch 20: val_loss improved from 0.71592 to 0.64001, saving model to radha_Beta.h5\n",
      "134/134 [==============================] - 59s 438ms/step - loss: 0.1719 - accuracy: 0.9867 - auc: 0.9992 - val_loss: 0.6400 - val_accuracy: 0.9121 - val_auc: 0.9704\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss='categorical_crossentropy',\n",
    "                   optimizer=RMSprop(learning_rate=0.0001),\n",
    "                   metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "history1 = model1.fit(train_generator,\n",
    "                         steps_per_epoch=num_train_samples//batch_size,\n",
    "                         epochs=epochs,\n",
    "                         callbacks=callbacks,\n",
    "                         validation_data=val_generator,\n",
    "                         validation_steps=num_val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fc06b8a-142d-492a-9a15-2799ef6455c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 545 images belonging to 5 classes.\n",
      "18/18 [==============================] - 8s 486ms/step\n",
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "                 AMD       1.00      0.94      0.97        79\n",
      "            cataract       0.91      0.95      0.93       105\n",
      "diabetic_retinopathy       0.87      0.96      0.91       121\n",
      "            glaucoma       0.89      0.86      0.88       102\n",
      "              normal       0.89      0.83      0.86       138\n",
      "\n",
      "            accuracy                           0.90       545\n",
      "           macro avg       0.91      0.91      0.91       545\n",
      "        weighted avg       0.90      0.90      0.90       545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "# Assuming you have test data in a separate directory\n",
    "test_data_dir = \"/home/admin1/dataset/test\"\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_data_dir,\n",
    "                                                  target_size=(img_height, img_width),\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  shuffle=False,\n",
    "                                                  class_mode='categorical')\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model1.predict(test_generator, steps=len(test_generator), verbose=1)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "y_pred_classes = [np.argmax(pred) for pred in y_pred]\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "# Get class labels\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_classes, y_pred_classes, target_names=class_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ae2c081-2084-47e1-babe-baf0a7523ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = history1\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "# Plotting the accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Saving the accuracy plot\n",
    "if not os.path.exists('graphs'):\n",
    "    os.makedirs('graphs')\n",
    "plt.savefig('graphs/EfficientNet accuracy.png')\n",
    "\n",
    "# Plotting the loss\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "# Saving the loss plot\n",
    "if not os.path.exists('graphs'):\n",
    "    os.makedirs('graphs')\n",
    "plt.savefig('graphs/EfficientNet loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92db7b09-eb72-4720-9ea0-b149e24947b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
